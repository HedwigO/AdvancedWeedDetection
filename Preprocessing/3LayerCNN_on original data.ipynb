{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IhX3Mrf6oSrw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sf4jw6dRo_SP",
        "outputId": "445e408b-64d0-4c36-a17b-03ca5530fb23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Many thanks to the dataset resource here: https://github.com/wittyicon29/WeedWatch-Weed-Detection-using-CNN/tree/main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CjSGqvRYtGyy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Directory containing your images\n",
        "image_data_dir = \"/content/drive/My Drive/CNN/Dataset/train_images\"\n",
        "# Load image filenames\n",
        "image_filenames = os.listdir(image_data_dir)\n",
        "\n",
        "# Load the labels CSV file\n",
        "labels_data = pd.read_csv(\"/content/drive/My Drive/CNN/Dataset/labels.csv\")\n",
        "# Assuming 'image_filename' is the column name in your CSV that contains the filenames\n",
        "label_filenames = labels_data['image_filename'].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I add the following steps because the original dataset has some images without labels. So I deleted those unmatched images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI3jIou4tI6r",
        "outputId": "106d4da1-0044-4385-fbbb-09f3da97e757"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unmatched images: []\n"
          ]
        }
      ],
      "source": [
        "# Find images without a corresponding label\n",
        "unmatched_images = [img for img in image_filenames if img not in label_filenames]\n",
        "print(\"Unmatched images:\", unmatched_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whM5Is2ztLRO",
        "outputId": "d5bec771-2ba1-4b3e-c3ad-a02f5d368680"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Remaining images count: 916\n"
          ]
        }
      ],
      "source": [
        "# Proceed to delete unmatched images\n",
        "for img in unmatched_images:\n",
        "    os.remove(os.path.join(image_data_dir, img))\n",
        "    print(f\"Deleted: {img}\")\n",
        "\n",
        "# Optionally, recheck what remains in the directory\n",
        "remaining_images = os.listdir(image_data_dir)\n",
        "print(\"Remaining images count:\", len(remaining_images))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2vNkdF_JokC-"
      },
      "outputs": [],
      "source": [
        "# Load the image dataset (assuming it's already preprocessed)\n",
        "image_data_dir = \"/content/drive/My Drive/CNN/Dataset/train_images\"\n",
        "image_filenames = os.listdir(image_data_dir)\n",
        "image_data = []\n",
        "for filename in image_filenames:\n",
        "    image_path = os.path.join(image_data_dir, filename)\n",
        "    image = cv2.imread(image_path)\n",
        "    image_data.append(image)\n",
        "image_data = np.array(image_data)\n",
        "\n",
        "# Load the labels CSV file\n",
        "labels_data = pd.read_csv(\"/content/drive/My Drive/CNN/Dataset/labels.csv\")\n",
        "\n",
        "# Merge the image dataset with the labels based on a common key, such as the image filename\n",
        "combined_data = pd.merge(labels_data, pd.DataFrame({\"image_filename\": image_filenames}), on=\"image_filename\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DsPEa3yXp318"
      },
      "outputs": [],
      "source": [
        "# Prepare the combined dataset for training\n",
        "X = image_data\n",
        "y = to_categorical(combined_data[\"label\"])\n",
        "\n",
        "# Split the combined dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n",
        "\n",
        "datagen.fit(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XRuQZWzEp6vI"
      },
      "outputs": [],
      "source": [
        "# Design the CNN model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation=\"relu\", input_shape=(image_data.shape[1:])))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dense(2, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcmtT-gGoZzx",
        "outputId": "e5c9824a-3017-4034-c100-d492daf63293"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "46/46 [==============================] - 75s 1s/step - loss: 120.2161 - accuracy: 0.5219 - val_loss: 0.7219 - val_accuracy: 0.5435\n",
            "Epoch 2/3\n",
            "46/46 [==============================] - 48s 1s/step - loss: 0.7009 - accuracy: 0.5410 - val_loss: 0.6952 - val_accuracy: 0.5435\n",
            "Epoch 3/3\n",
            "46/46 [==============================] - 53s 1s/step - loss: 0.6994 - accuracy: 0.5451 - val_loss: 0.6918 - val_accuracy: 0.5380\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d48b7d73dc0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compile the model\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model on the augmented training dataset\n",
        "### I pick 3 epochs just for a try. Should train more epochs!\n",
        "model.fit(datagen.flow(X_train, y_train, batch_size=16), epochs=3, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcbLuAvct1hp",
        "outputId": "34bda338-84bb-42e0-f122-5ca750082bd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.6917865872383118\n",
            "Test accuracy: 0.5380434989929199\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model's performance on the testing dataset\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
